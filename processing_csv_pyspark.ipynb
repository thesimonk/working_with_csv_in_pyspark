{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzrIAr4NhtC9hDaNGGf8c9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesimonk/working_with_csv_in_pyspark/blob/master/processing_csv_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession as ss\n",
        "# import SparkSession, the main entry point to Spark functionality\n",
        "# aliasing it as 'ss' is optional and just shortens later references\n",
        "\n",
        "spark = ss.builder \\\n",
        "    .appName('CSV Processing') \\\n",
        "    .getOrCreate()\n",
        "# ss.builder        - starts configuring a Spark application\n",
        "# .appName(...)     - sets the application name (visible in Spark UI)\n",
        "#                     (optional but recommended for tracking jobs)\n",
        "# .getOrCreate()    - returns an existing SparkSession if one already exists,\n",
        "#                     otherwise creates a new one\n",
        "\n",
        "data = spark.read.csv(\n",
        "    '/content/sample_data/california_housing_train.csv',\n",
        "    header=True,        # header=True - first row contains column names\n",
        "                        # header=False - Spark assigns column names like _c0, _c1, ...\n",
        "    inferSchema=True    # inferSchema=True - Spark infers column data types (int, double, etc.)\n",
        "                        # inferSchema=False - all columns are read as strings (default)\n",
        ")\n",
        "# spark.read        - DataFrameReader used for loading data\n",
        "# .csv(...)         - reads a CSV file from local disk, HDFS, or cloud storage\n",
        "# the result is a Spark DataFrame distributed across partitions\n",
        "\n",
        "data.show()\n",
        "# show()            - triggers a Spark action (lazy evaluation ends here)\n",
        "#                     Displays the first 20 rows by default\n",
        "# show(n)           - display the first n rows (e.g., show(5))\n",
        "# show(truncate)   - truncate long columns (default=True)\n",
        "# show(n, truncate)- control both row count and truncation"
      ],
      "metadata": {
        "id": "6YfXEGy3aYg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669b02a5-01b1-4907-f2a1-e92bc3e094b5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check column data types\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ7WNlkxBxA4",
        "outputId": "697d2fd6-257a-4cd7-80cb-5092c3dd2b23"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change a column from one data type to another\n",
        "from pyspark.sql.functions import col # ideally imported at the top (first cell)\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"total_rooms\", col(\"total_rooms\").cast(\"int\")\n",
        ")\n",
        "\n",
        "# common type conversions\n",
        "    # .cast(\"int\")\n",
        "    # .cast(\"double\")\n",
        "    # .cast(\"float\")\n",
        "    # .cast(\"string\")\n",
        "    # .cast(\"boolean\")\n",
        "    # .cast(\"date\")\n",
        "    # .cast(\"timestamp\")\n",
        "\n",
        "# change multiple columns at once\n",
        "data = data.select(\n",
        "    col(\"total_bedrooms\").cast(\"int\"),\n",
        "    col(\"median_house_value\").cast(\"int\"),\n",
        "    *[c for c in data.columns if c not in [\"total_bedrooms\", \"median_house_value\"]]\n",
        ")\n",
        "\n",
        "data.show(5)\n",
        "data.printSchema()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etactF_MHI96",
        "outputId": "c7030344-e804-4924-8389-9840f78d522f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "|total_bedrooms|median_house_value|longitude|latitude|housing_median_age|total_rooms|population|households|median_income|\n",
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "|          1283|             66900|  -114.31|   34.19|              15.0|       5612|    1015.0|     472.0|       1.4936|\n",
            "|          1901|             80100|  -114.47|    34.4|              19.0|       7650|    1129.0|     463.0|         1.82|\n",
            "|           174|             85700|  -114.56|   33.69|              17.0|        720|     333.0|     117.0|       1.6509|\n",
            "|           337|             73400|  -114.57|   33.64|              14.0|       1501|     515.0|     226.0|       3.1917|\n",
            "|           326|             65500|  -114.57|   33.57|              20.0|       1454|     624.0|     262.0|        1.925|\n",
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- total_bedrooms: integer (nullable = true)\n",
            " |-- median_house_value: integer (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: integer (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# round a column to 2 decimal places\n",
        "from pyspark.sql.functions import round\n",
        "data = data.withColumn(\n",
        "    \"median_income\",\n",
        "    round(col(\"median_income\"),2)\n",
        ")\n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlYoMG-VMvAL",
        "outputId": "bc9f6d2e-a09e-47ad-d838-c4c33a1c98f1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "|total_bedrooms|median_house_value|longitude|latitude|housing_median_age|total_rooms|population|households|median_income|\n",
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "|          1283|             66900|  -114.31|   34.19|              15.0|       5612|    1015.0|     472.0|         1.49|\n",
            "|          1901|             80100|  -114.47|    34.4|              19.0|       7650|    1129.0|     463.0|         1.82|\n",
            "|           174|             85700|  -114.56|   33.69|              17.0|        720|     333.0|     117.0|         1.65|\n",
            "|           337|             73400|  -114.57|   33.64|              14.0|       1501|     515.0|     226.0|         3.19|\n",
            "|           326|             65500|  -114.57|   33.57|              20.0|       1454|     624.0|     262.0|         1.93|\n",
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter by a column\n",
        "data = data.filter(data.median_income > 2.00)\n",
        "\n",
        "# using col() (recommended style)\n",
        "    # from pyspark.sql.functions import col\n",
        "    # df_filtered = data.filter(col(\"median_income\") > 2.0)\n",
        "\n",
        "# filter using SQL-style expressions\n",
        "    # data.filter(\"median_income > 2.0 AND housing_median_age < 40\")\n",
        "\n",
        "# filter string columns\n",
        "    # df.filter(col(\"ocean_proximity\") == \"NEAR BAY\")\n",
        "    # df.filter(col(\"ocean_proximity\").like(\"%BAY%\"))\n",
        "    # df.filter(col(\"ocean_proximity\").startswith(\"NEAR\"))\n",
        "    # df.filter(col(\"ocean_proximity\").isin(\"NEAR BAY\", \"INLAND\"))\n",
        "\n",
        "# filter by range\n",
        "    # data.filter(col(\"median_income\").between(3.0, 6.0))\n",
        "\n",
        "# filter NULL/NOT NULL values\n",
        "    # data.filter(col(\"total_bedrooms\").isNull())\n",
        "    # data.filter(col(\"total_bedrooms\").isNotNull())\n",
        "\n",
        "# filter using lists (IN/NOT IN)\n",
        "    # data.filter(col(\"housing_median_age\").isin([10, 20, 30]))\n",
        "    # negation:\n",
        "      # data.filter(~col(\"housing_median_age\").isin([10, 20, 30]))\n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu7rmrmjPfIx",
        "outputId": "f91fa221-744c-43cb-fb1a-8605196cb2cb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "|total_bedrooms|median_house_value|longitude|latitude|housing_median_age|total_rooms|population|households|median_income|\n",
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "|           337|             73400|  -114.57|   33.64|              14.0|       1501|     515.0|     226.0|         3.19|\n",
            "|           236|             74000|  -114.58|   33.63|              29.0|       1387|     671.0|     239.0|         3.34|\n",
            "|           680|             82400|  -114.58|   33.61|              25.0|       2907|    1841.0|     633.0|         2.68|\n",
            "|          1175|             58400|  -114.59|   33.61|              34.0|       4789|    3134.0|    1056.0|         2.18|\n",
            "|           309|             48100|   -114.6|   34.83|              46.0|       1497|     787.0|     271.0|         2.19|\n",
            "+--------------+------------------+---------+--------+------------------+-----------+----------+----------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by on data frame\n",
        "from pyspark.sql.functions import avg, round\n",
        "data = (\n",
        "    data\n",
        "    .groupBy(\"latitude\")\n",
        "    .agg(round(avg(\"median_income\"), 2).alias(\"avg_median_income\"))\n",
        ")\n",
        "\n",
        "# common aggregations\n",
        "    # from pyspark.sql.functions import (\n",
        "    #     count, sum, avg, min, max, mean\n",
        "    # )\n",
        "\n",
        "    # df.groupBy(\"ocean_proximity\").agg(\n",
        "    #     count(\"*\").alias(\"row_count\"),\n",
        "    #     avg(\"median_income\").alias(\"avg_income\"),\n",
        "    #     min(\"median_income\").alias(\"min_income\"),\n",
        "    #     max(\"median_income\").alias(\"max_income\"),\n",
        "    #     sum(\"population\").alias(\"total_population\")\n",
        "    # ).show()\n",
        "\n",
        "\n",
        "# most common pattern\n",
        "    # df.groupBy(\"column\").agg(\n",
        "    #     avg(\"value\").alias(\"avg_value\"),\n",
        "    #     count(\"*\").alias(\"count\")\n",
        "    # )\n",
        "\n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYc6JuNmVuYt",
        "outputId": "3f3c56cd-ab39-41ce-d8e0-15b7a9261bf1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------+\n",
            "|latitude|avg_median_income|\n",
            "+--------+-----------------+\n",
            "|   35.17|             3.49|\n",
            "|   38.61|             3.36|\n",
            "|   37.81|             4.88|\n",
            "|   40.53|             2.35|\n",
            "|   37.23|             6.07|\n",
            "+--------+-----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DboLeK68WqO_"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}