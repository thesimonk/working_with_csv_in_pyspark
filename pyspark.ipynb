{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────\n",
        "#          PySpark CSV + Common Operations\n",
        "#           (2025–2026 style - most used patterns)\n",
        "# ───────────────────────────────────────────────\n",
        "\n",
        "# === 1. Basic session creation (Spark 3.x ) =============================\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CSV_cheatsheet_example\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# sc = spark.sparkContext\n",
        "\n",
        "# === 2. Reading CSV files ===============================================\n",
        "df = spark.read.csv(\"path/to/file.csv\", header=True, inferSchema=True)\n",
        "# or more explicit / safer version:\n",
        "df = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"encoding\", \"UTF-8\") \\\n",
        "    .option(\"escape\", '\"') \\\n",
        "    .option(\"quote\", '\"') \\\n",
        "    .option(\"mode\", \"PERMISSIVE\") \\\n",
        "    .csv(\"data/*.csv\")\n",
        "\n",
        "# very common modern pattern (especially 2024–2026):\n",
        "df = spark.read.option(\"header\",True).csv(\"s3://bucket/folder/*.csv.gz\")\n",
        "\n",
        "# === 3. Quick inspection ================================================\n",
        "df.printSchema()                                             # shows column names + inferred types\n",
        "df.show(5, truncate=40, vertical=False)                      # vertical=True is great for wide tables\n",
        "df.select(\"*\").limit(20).toPandas()                          # careful – only for small results!\n",
        "\n",
        "# get row count (action!)\n",
        "df.count()\n",
        "\n",
        "# === 4. Most useful column operations ===================================\n",
        "from pyspark.sql.functions import col, column\n",
        "\n",
        "# Select & rename\n",
        "df.select(\"id\", \"name\", col(\"salary\").alias(\"monthly_salary\"))\n",
        "\n",
        "# Filter (two equivalent styles)\n",
        "df.filter(\"age > 30 AND salary < 80000\")\n",
        "df.filter((col(\"age\") > 30) & (col(\"salary\") < 80000))\n",
        "\n",
        "# Add / replace column\n",
        "from pyspark.sql.functions import lit, when, concat_ws, lower, upper\n",
        "\n",
        "df = df.withColumn(\"country\", lit(\"Kenya\"))                  # constant value\n",
        "df = df.withColumn(\"senior\", when(col(\"age\") >= 35, True).otherwise(False))\n",
        "df = df.withColumn(\"full_name\", concat_ws(\" \", \"first_name\", \"last_name\"))\n",
        "df = df.withColumn(\"email_lower\", lower(col(\"email\")))\n",
        "\n",
        "# === 5. Handling nulls / missing values ================================\n",
        "from pyspark.sql.functions import coalesce, isnan, when, count\n",
        "\n",
        "df = df.na.fill({\"salary\": 0, \"age\": -1})                    # fill nulls with specific values\n",
        "df = df.na.drop(\"any\")                                       # drop row if ANY column is null\n",
        "df = df.na.drop(\"all\", subset=[\"email\", \"phone\"])            # drop only if ALL listed cols null\n",
        "\n",
        "# count nulls per column (very useful pattern)\n",
        "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
        "\n",
        "# === 6. GroupBy + Aggregations (most frequent task) ====================\n",
        "from pyspark.sql.functions import count, sum, avg, min, max, countDistinct\n",
        "\n",
        "result = df.groupBy(\"department\", \"city\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"headcount\"),\n",
        "        countDistinct(\"employee_id\").alias(\"unique_employees\"),\n",
        "        sum(\"salary\").alias(\"total_salary\"),\n",
        "        avg(\"salary\").alias(\"avg_salary\"),\n",
        "        max(\"age\").alias(\"oldest\")\n",
        "    ) \\\n",
        "    .orderBy(\"total_salary\", ascending=False)\n",
        "\n",
        "result.show(truncate=False)\n",
        "\n",
        "# withColumn + agg pattern (very common)\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "df.groupBy(\"department\").agg(\n",
        "    round(avg(\"salary\"), 0).alias(\"avg_salary_round\"),\n",
        "    (sum(\"salary\") / 1000000).alias(\"salary_millions\")\n",
        ").orderBy(\"avg_salary_round\", ascending=False)\n",
        "\n",
        "# === 7. Joins (most common types) =======================================\n",
        "orders = spark.read.csv(\"orders.csv\", header=True, inferSchema=True)\n",
        "customers = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# inner (default)\n",
        "df_joined = orders.join(customers, \"customer_id\", \"inner\")\n",
        "\n",
        "# left / right / full / anti / cross\n",
        "df_left  = orders.join(customers, \"customer_id\", \"left\")\n",
        "df_anti  = orders.join(customers, \"customer_id\", \"left_anti\")   # rows in orders without match\n",
        "\n",
        "# multi-column join\n",
        "# df.join(other_df,\n",
        "#         (df.customer_id == other_df.id) & (df.country == other_df.country),\n",
        "#         \"left\")\n",
        "\n",
        "# === 8. Window functions (ranking, running totals, etc) ================\n",
        "from pyspark.sql.window import Window\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "window_spec = Window.partitionBy(\"department\").orderBy(F.desc(\"salary\"))\n",
        "\n",
        "df_with_rank = df.withColumn(\"rank\", F.rank().over(window_spec)) \\\n",
        "                 .withColumn(\"dense_rank\", F.dense_rank().over(window_spec)) \\\n",
        "                 .withColumn(\"row_number\", F.row_number().over(window_spec))\n",
        "\n",
        "# running total example\n",
        "window_cum = Window.partitionBy(\"department\").orderBy(\"hire_date\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "df = df.withColumn(\"cumulative_salary\", F.sum(\"salary\").over(window_cum))\n",
        "\n",
        "# === 9. Writing results =================================================\n",
        "# most common formats\n",
        "df.write.mode(\"overwrite\").parquet(\"s3://bucket/results/employees.parquet/\")\n",
        "df.write.mode(\"append\").partitionBy(\"year\",\"month\").parquet(\"output/\")\n",
        "\n",
        "# CSV output (less common in big data, but still used)\n",
        "df.write \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"compression\", \"gzip\") \\\n",
        "    .csv(\"output/my_result_csv/\")\n",
        "\n",
        "# single file output (small data only!)\n",
        "df.coalesce(1).write.mode(\"overwrite\").csv(\"small_result/\", header=True)\n",
        "\n",
        "# === 10. Quick one-liners you use all the time ========================\n",
        "df.cache()                              # or .persist() — very important for iterative work\n",
        "df.unpersist()                          # free memory\n",
        "\n",
        "df.createOrReplaceTempView(\"employees\") # then use SQL\n",
        "spark.sql(\"SELECT department, AVG(salary) FROM employees GROUP BY department\")\n",
        "\n",
        "df.explain()                            # see physical + logical plan\n",
        "df.explain(\"extended\")                  # more detailed\n",
        "\n",
        "# Stop session when finished\n",
        "spark.stop()                          # usually done automatically in notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5QkshukqOSPF",
        "outputId": "20c67186-c5c4-4ad6-b518-16fe9e8a11d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           _c0        _c1                 _c2          _c3             _c4  \\\n",
              "0    longitude   latitude  housing_median_age  total_rooms  total_bedrooms   \n",
              "1  -122.050000  37.370000           27.000000  3885.000000      661.000000   \n",
              "2  -118.300000  34.260000           43.000000  1510.000000      310.000000   \n",
              "3  -117.810000  33.780000           27.000000  3589.000000      507.000000   \n",
              "4  -118.360000  33.820000           28.000000    67.000000       15.000000   \n",
              "\n",
              "           _c5         _c6            _c7                 _c8  \n",
              "0   population  households  median_income  median_house_value  \n",
              "1  1537.000000  606.000000       6.608500       344700.000000  \n",
              "2   809.000000  277.000000       3.599000       176500.000000  \n",
              "3  1484.000000  495.000000       5.793400       270500.000000  \n",
              "4    49.000000   11.000000       6.135900       330000.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58e97654-b700-41c9-95b1-273a50f30117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_c0</th>\n",
              "      <th>_c1</th>\n",
              "      <th>_c2</th>\n",
              "      <th>_c3</th>\n",
              "      <th>_c4</th>\n",
              "      <th>_c5</th>\n",
              "      <th>_c6</th>\n",
              "      <th>_c7</th>\n",
              "      <th>_c8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>longitude</td>\n",
              "      <td>latitude</td>\n",
              "      <td>housing_median_age</td>\n",
              "      <td>total_rooms</td>\n",
              "      <td>total_bedrooms</td>\n",
              "      <td>population</td>\n",
              "      <td>households</td>\n",
              "      <td>median_income</td>\n",
              "      <td>median_house_value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.050000</td>\n",
              "      <td>37.370000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>3885.000000</td>\n",
              "      <td>661.000000</td>\n",
              "      <td>1537.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>6.608500</td>\n",
              "      <td>344700.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-118.300000</td>\n",
              "      <td>34.260000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>1510.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>809.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>3.599000</td>\n",
              "      <td>176500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-117.810000</td>\n",
              "      <td>33.780000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>3589.000000</td>\n",
              "      <td>507.000000</td>\n",
              "      <td>1484.000000</td>\n",
              "      <td>495.000000</td>\n",
              "      <td>5.793400</td>\n",
              "      <td>270500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-118.360000</td>\n",
              "      <td>33.820000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>6.135900</td>\n",
              "      <td>330000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58e97654-b700-41c9-95b1-273a50f30117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58e97654-b700-41c9-95b1-273a50f30117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58e97654-b700-41c9-95b1-273a50f30117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3001,\n  \"fields\": [\n    {\n      \"column\": \"_c0\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 608,\n        \"samples\": [\n          \"-121.900000\",\n          \"-118.020000\",\n          \"-114.980000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 588,\n        \"samples\": [\n          \"33.220000\",\n          \"38.410000\",\n          \"35.290000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 53,\n        \"samples\": [\n          \"30.000000\",\n          \"20.000000\",\n          \"3.000000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2216,\n        \"samples\": [\n          \"1489.000000\",\n          \"142.000000\",\n          \"7803.000000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1056,\n        \"samples\": [\n          \"716.000000\",\n          \"1240.000000\",\n          \"180.000000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1803,\n        \"samples\": [\n          \"2239.000000\",\n          \"1247.000000\",\n          \"738.000000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c6\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1027,\n        \"samples\": [\n          \"814.000000\",\n          \"629.000000\",\n          \"722.000000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c7\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2579,\n        \"samples\": [\n          \"1.725000\",\n          \"5.694900\",\n          \"5.968300\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_c8\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1785,\n        \"samples\": [\n          \"71900.000000\",\n          \"262400.000000\",\n          \"354200.000000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YfXEGy3aYg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}